import torch
import torch.nn as nn
from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup
from torch.utils.data import DataLoader
from typing import List, Dict, Any, Optional, Callable
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import time
import os

class Trainer:
    """æ¨¡åž‹è®­ç»ƒå™¨"""
    
    def __init__(self, model: nn.Module, device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        self.model = model
        self.device = device
        self.model.to(device)
    
    def train_epoch(self, train_loader: DataLoader, optimizer: torch.optim.Optimizer, 
                   scheduler: Optional[Any] = None) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        all_preds = []
        all_labels = []
        
        for batch_idx, batch in enumerate(train_loader):
            # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs['loss']
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            if scheduler:
                scheduler.step()
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_loss += loss.item()
            
            # èŽ·å–é¢„æµ‹ç»“æžœ
            preds = torch.argmax(outputs['logits'], dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        avg_loss = total_loss / len(train_loader)
        accuracy = accuracy_score(all_labels, all_preds)
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy
        }
    
    def evaluate(self, val_loader: DataLoader) -> Dict[str, float]:
        """æ¨¡åž‹è¯„ä¼°"""
        self.model.eval()
        total_loss = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
                loss = outputs['loss']
                
                total_loss += loss.item()
                
                preds = torch.argmax(outputs['logits'], dim=1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        avg_loss = total_loss / len(val_loader)
        accuracy = accuracy_score(all_labels, all_preds)
        precision = precision_score(all_labels, all_preds, average='weighted')
        recall = recall_score(all_labels, all_preds, average='weighted')
        f1 = f1_score(all_labels, all_preds, average='weighted')
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1
        }
    
    def predict(self, texts: List[str], tokenizer, max_length: int = 512) -> List[int]:
        """é¢„æµ‹"""
        self.model.eval()
        predictions = []
        
        with torch.no_grad():
            for text in texts:
                # ç¼–ç æ–‡æœ¬
                encoding = tokenizer(
                    text,
                    truncation=True,
                    padding='max_length',
                    max_length=max_length,
                    return_tensors='pt'
                )
                
                input_ids = encoding['input_ids'].to(self.device)
                attention_mask = encoding['attention_mask'].to(self.device)
                
                # é¢„æµ‹
                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
                pred = torch.argmax(outputs['logits'], dim=1)
                predictions.append(pred.cpu().item())
        
        return predictions

def train_model(
    model: nn.Module, 
    train_loader: DataLoader, 
    val_loader: DataLoader, 
    epochs: int = 3, 
    learning_rate: float = 2e-5, 
    warmup_steps: int = 0,
    progress_callback: Optional[Callable[[int, int, float], None]] = None,
    device: str = None  # æ–°å¢ž: å…è®¸æŒ‡å®šè®¾å¤‡
) -> Dict[str, Any]:
    """
    è®­ç»ƒæ¨¡åž‹
    
    Args:
        model: æ¨¡åž‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        epochs: è®­ç»ƒè½®æ•°
        learning_rate: å­¦ä¹ çŽ‡
        warmup_steps: é¢„çƒ­æ­¥æ•°
        progress_callback: è¿›åº¦å›žè°ƒå‡½æ•°ï¼Œå‚æ•°ä¸º (å½“å‰eepoch, æ€»epochs, è¿›åº¦ç™¾åˆ†æ¯”)
        device: è®¾å¤‡ç±»åž‹ï¼Œcuda æˆ– cpuï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹
    """
    # è®¾å¤‡é€‰æ‹©: ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ deviceï¼Œå¦åˆ™è‡ªåŠ¨æ£€æµ‹
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    print(f"ðŸ’» è®­ç»ƒè®¾å¤‡: {device.upper()}")
    if device == "cuda":
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    trainer = Trainer(model, device)    
    # ä¼˜åŒ–å™¨
    optimizer = AdamW(model.parameters(), lr=learning_rate)
    
    # å­¦ä¹ çŽ‡è°ƒåº¦å™¨
    total_steps = len(train_loader) * epochs
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=warmup_steps,
        num_training_steps=total_steps
    )
    
    # è®­ç»ƒåŽ†å²
    history = {
        'train_loss': [],
        'train_accuracy': [],
        'val_loss': [],
        'val_accuracy': [],
        'val_precision': [],
        'val_recall': [],
        'val_f1': []
    }
    
    best_val_f1 = 0
    best_model_state = None
    
    for epoch in range(epochs):
        print(f"Epoch {epoch + 1}/{epochs}")
        
        # è®¡ç®—å½“å‰è¿›åº¦å¹¶è°ƒç”¨å›žè°ƒ
        progress = ((epoch + 0.5) / epochs) * 100  # è®­ç»ƒä¸­é—´ç‚¹
        if progress_callback:
            try:
                progress_callback(epoch + 1, epochs, progress)
            except Exception as e:
                print(f"Progress callback error: {e}")
        
        # è®­ç»ƒ
        train_metrics = trainer.train_epoch(train_loader, optimizer, scheduler)
        history['train_loss'].append(train_metrics['loss'])
        history['train_accuracy'].append(train_metrics['accuracy'])
        
        # éªŒè¯
        val_metrics = trainer.evaluate(val_loader)
        history['val_loss'].append(val_metrics['loss'])
        history['val_accuracy'].append(val_metrics['accuracy'])
        history['val_precision'].append(val_metrics['precision'])
        history['val_recall'].append(val_metrics['recall'])
        history['val_f1'].append(val_metrics['f1_score'])
        
        print(f"Train Loss: {train_metrics['loss']:.4f}, Train Acc: {train_metrics['accuracy']:.4f}")
        print(f"Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.4f}")
        print(f"Val F1: {val_metrics['f1_score']:.4f}")
        
        # æ¯ä¸ªepochç»“æŸåŽæ›´æ–°è¿›åº¦
        progress = ((epoch + 1) / epochs) * 100
        if progress_callback:
            try:
                progress_callback(epoch + 1, epochs, progress)
            except Exception as e:
                print(f"Progress callback error: {e}")
        
        # ä¿å­˜æœ€ä½³æ¨¡åž‹
        if val_metrics['f1_score'] > best_val_f1:
            best_val_f1 = val_metrics['f1_score']
            best_model_state = model.state_dict()
    
    # åŠ è½½æœ€ä½³æ¨¡åž‹
    if best_model_state:
        model.load_state_dict(best_model_state)
    
    return history