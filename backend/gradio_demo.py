import gradio as gr
import torch
import pandas as pd
import numpy as np
from transformers import pipeline
from typing import List, Dict, Any
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

class GradioDemo:
    """Gradio æ¼”ç¤ºç•Œé¢"""
    
    def __init__(self):
        self.models = {}
        self.loaded_model = None
        self.loaded_tokenizer = None
    
    def load_model(self, model_path: str):
        """åŠ è½½æ¨¡å‹"""
        try:
            from modeling_bert import load_saved_model, load_tokenizer
            self.loaded_model = load_saved_model(model_path)
            self.loaded_tokenizer = load_tokenizer()
            return f"æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}"
        except Exception as e:
            return f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
    
    def predict_text(self, text: str) -> Dict[str, Any]:
        """æ–‡æœ¬åˆ†ç±»é¢„æµ‹"""
        if not self.loaded_model or not self.loaded_tokenizer:
            return {"error": "è¯·å…ˆåŠ è½½æ¨¡å‹"}
        
        try:
            from trainer import Trainer
            trainer = Trainer(self.loaded_model)
            predictions = trainer.predict([text], self.loaded_tokenizer)
            
            # è·å–é¢„æµ‹æ¦‚ç‡
            encoding = self.loaded_tokenizer(
                text,
                truncation=True,
                padding='max_length',
                max_length=512,
                return_tensors='pt'
            )
            
            with torch.no_grad():
                outputs = self.loaded_model(
                    input_ids=encoding['input_ids'].to(self.loaded_model.device),
                    attention_mask=encoding['attention_mask'].to(self.loaded_model.device)
                )
                probabilities = torch.softmax(outputs['logits'], dim=1)
                probabilities = probabilities.cpu().numpy()[0]
            
            return {
                "prediction": int(predictions[0]),
                "probabilities": probabilities.tolist(),
                "confidence": float(np.max(probabilities))
            }
        except Exception as e:
            return {"error": f"é¢„æµ‹å¤±è´¥: {str(e)}"}
    
    def create_training_dashboard(self, history: Dict[str, Any]) -> plt.Figure:
        """åˆ›å»ºè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(history['train_loss'], label='è®­ç»ƒæŸå¤±')
        axes[0, 0].plot(history['val_loss'], label='éªŒè¯æŸå¤±')
        axes[0, 0].set_title('æŸå¤±æ›²çº¿')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(history['train_accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡')
        axes[0, 1].plot(history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡')
        axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        
        # F1åˆ†æ•°æ›²çº¿
        axes[1, 0].plot(history['val_f1'], label='éªŒè¯F1åˆ†æ•°', color='green')
        axes[1, 0].set_title('F1åˆ†æ•°æ›²çº¿')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('F1 Score')
        axes[1, 0].legend()
        
        # æ··æ·†çŸ©é˜µï¼ˆç¤ºä¾‹ï¼‰
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ··æ·†çŸ©é˜µå¯è§†åŒ–
        axes[1, 1].text(0.5, 0.5, 'æ··æ·†çŸ©é˜µå¯è§†åŒ–', ha='center', va='center', fontsize=16)
        axes[1, 1].set_title('æ··æ·†çŸ©é˜µ')
        
        plt.tight_layout()
        return fig

def create_gradio_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    demo = GradioDemo()
    
    with gr.Blocks(title="Agent Finetune Demo", theme="soft") as interface:
        gr.Markdown("# ğŸ¤– Agent å¾®è°ƒæ¼”ç¤ºå¹³å°")
        gr.Markdown("åŸºäº Transformers çš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹å¾®è°ƒæ¼”ç¤º")
        
        with gr.Tab("æ¨¡å‹é¢„æµ‹"):
            with gr.Row():
                with gr.Column():
                    model_path_input = gr.Textbox(
                        label="æ¨¡å‹è·¯å¾„",
                        placeholder="è¾“å…¥æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ï¼šmodels/my_model.pthï¼‰",
                        value="models/sample_model.pth"
                    )
                    load_model_btn = gr.Button("åŠ è½½æ¨¡å‹")
                    load_status = gr.Textbox(label="åŠ è½½çŠ¶æ€", interactive=False)
                
                with gr.Column():
                    text_input = gr.Textbox(
                        label="è¾“å…¥æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥è¦åˆ†ç±»çš„æ–‡æœ¬...",
                        lines=3
                    )
                    predict_btn = gr.Button("é¢„æµ‹")
            
            with gr.Row():
                prediction_output = gr.JSON(label="é¢„æµ‹ç»“æœ")
                
            # ç»‘å®šäº‹ä»¶
            load_model_btn.click(
                fn=demo.load_model,
                inputs=model_path_input,
                outputs=load_status
            )
            predict_btn.click(
                fn=demo.predict_text,
                inputs=text_input,
                outputs=prediction_output
            )
        
        with gr.Tab("è®­ç»ƒå¯è§†åŒ–"):
            gr.Markdown("## è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–")
            
            # ç¤ºä¾‹å†å²æ•°æ®
            example_history = {
                'train_loss': [0.8, 0.6, 0.4, 0.3, 0.25],
                'val_loss': [0.9, 0.7, 0.5, 0.4, 0.35],
                'train_accuracy': [0.65, 0.75, 0.82, 0.88, 0.92],
                'val_accuracy': [0.62, 0.72, 0.78, 0.84, 0.88],
                'val_f1': [0.61, 0.71, 0.77, 0.83, 0.87]
            }
            
            plot_output = gr.Plot(label="è®­ç»ƒè¿‡ç¨‹å›¾è¡¨")
            
            # æ˜¾ç¤ºç¤ºä¾‹å›¾è¡¨
            interface.load(
                fn=lambda: demo.create_training_dashboard(example_history),
                outputs=plot_output
            )
        
        with gr.Tab("æ¨¡å‹ä¿¡æ¯"):
            gr.Markdown("## æ”¯æŒçš„æ¨¡å‹ç±»å‹")
            
            model_info = {
                "BERT-base": "åŸºäºBERTçš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹ï¼Œé€‚ç”¨äºé€šç”¨æ–‡æœ¬åˆ†ç±»ä»»åŠ¡",
                "BERT-large": "æ›´å¤§çš„BERTæ¨¡å‹ï¼Œé€‚åˆå¤æ‚åˆ†ç±»ä»»åŠ¡",
                "RoBERTa": "ä¼˜åŒ–çš„BERTå˜ä½“ï¼Œåœ¨å¤šä¸ªNLPä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚",
                "DistilBERT": "è½»é‡çº§BERTæ¨¡å‹ï¼Œæ¨ç†é€Ÿåº¦å¿«ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ"
            }
            
            for model_name, description in model_info.items():
                with gr.Group():
                    gr.Markdown(f"### {model_name}")
                    gr.Markdown(f"{description}")
    
    return interface

if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨ Gradio ç•Œé¢
    interface = create_gradio_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True
    )